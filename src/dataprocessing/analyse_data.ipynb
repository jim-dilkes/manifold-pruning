{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from itertools import repeat\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Test/Test_frequency_bin.json\", \"r\") as f:\n",
    "    json_file = json.load(f)\n",
    "open_word_tag = [\"JJ\", \"JJR\", \"JJS\", \"RB\", \"RBR\", \"RBS\", \"NN\", \"NNS\", \"NNP\", \"NNPS\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\", \"FW\"]\n",
    "open_tag_dict = {key:json_file[key] for key in open_word_tag}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:13<00:00,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "def filter_words(pos_dict, K):\n",
    "    words_full = []\n",
    "    for keys in pos_dict.keys():\n",
    "        words_full.extend(pos_dict[keys])\n",
    "    words_count = Counter(words_full)\n",
    "    output = [word for item, n in words_count.items() if n < K for word in repeat(item, n)]\n",
    "    for keys in tqdm(pos_dict.keys()):\n",
    "        for word in pos_dict[keys]:\n",
    "            if word in output:\n",
    "                pos_dict[keys].remove(word)\n",
    "    return pos_dict\n",
    "\n",
    "filtered_words = filter_words(open_tag_dict, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag_filter(pos_dict, N):\n",
    "    full_words = []\n",
    "    for key in pos_dict.keys():\n",
    "        full_words.extend(pos_dict[key])\n",
    "    full_words = list(set(full_words))\n",
    "    tmp = {key:list(set(pos_dict[key])) for key in pos_dict.keys()}\n",
    "    ambiguous_words = []\n",
    "    for word in full_words:\n",
    "        cnt = 0\n",
    "        for key in tmp.keys():\n",
    "            if word in tmp[key]:\n",
    "                cnt += 1\n",
    "            if cnt >= N:\n",
    "                ambiguous_words.append(word)\n",
    "                break\n",
    "\n",
    "    return ambiguous_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous_words = pos_tag_filter(filtered_words, 2)\n",
    "ambiguous_words_pos = {}\n",
    "for key in open_word_tag:\n",
    "    ambiguous_words_pos[key] = [word for word in filtered_words[key] if word in ambiguous_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(ambiguous_words)\n",
    "k = len(ambiguous_words_pos.keys())\n",
    "df = pd.DataFrame(np.zeros((n, k)), columns=open_word_tag, index=ambiguous_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29623\n"
     ]
    }
   ],
   "source": [
    "number_of_total_words = sum([len(ambiguous_words_pos[key]) for key in ambiguous_words_pos.keys()])\n",
    "print(number_of_total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in open_word_tag:\n",
    "    words_count = Counter(ambiguous_words_pos[tag])\n",
    "    vals = np.zeros(n)\n",
    "    for indx, word in enumerate(ambiguous_words):\n",
    "        vals[indx] = words_count.get(word, 0.0)\n",
    "    df[tag] = vals\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Test/Test_word_amb_tag.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tag_matrix = df.values\n",
    "tag_prob = np.sum(word_tag_matrix, axis=0)\n",
    "word_norm = (word_tag_matrix.T/word_tag_matrix.sum(axis=1)).T\n",
    "word_tag_norm = word_norm / tag_prob\n",
    "word_score = -np.sum(word_norm * np.log2(word_tag_norm, out=np.zeros_like(word_tag_norm), where=(word_tag_norm!=0)), axis=1)\n",
    "\n",
    "res = pd.DataFrame(np.zeros((n, 2)), columns=[\"Word\", \"Score\"])\n",
    "res[\"Word\"] = ambiguous_words\n",
    "res[\"Score\"] = word_score\n",
    "res = res.sort_values(by=[\"Score\"], ascending=False)\n",
    "res.to_csv('Test/Test_word_amb_score.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(sum((np.sum(word_tag_matrix, axis=1)/number_of_total_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "word_to_test = \"friar\"\n",
    "score = 0\n",
    "m = 0\n",
    "n = 0\n",
    "for tag in open_word_tag:\n",
    "    val = ambiguous_words_pos[tag].count(word_to_test)\n",
    "    score += val\n",
    "    if val != 0:\n",
    "        print(val)\n",
    "        print(tag)\n",
    "        n += 1\n",
    "    if val > m:\n",
    "        m = val\n",
    "print(score, n, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0\n",
      "jews        313\n",
      "americans   202\n",
      "christians  165\n",
      "islands     163\n",
      "ages        138\n",
      "...         ...\n",
      "celtics       1\n",
      "heroes        1\n",
      "sensations    1\n",
      "maldives      1\n",
      "problems      1\n",
      "\n",
      "[1231 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "word_counts = Counter(json_file[\"NNPS\"])\n",
    "df = pd.DataFrame.from_dict(word_counts, orient='index')\n",
    "print(df.sort_values(by=[0], ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10cf916465d97e2d34dfad3237a8b45f9d727932a6a602d5b42972fb56b0de9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
